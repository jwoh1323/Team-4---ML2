{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Factor Model with Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This model is copied from the HW1 solution posted by Kyra and extended to include regularization of the beta parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def readFile(f):\n",
    "  for l in open(f):\n",
    "    yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set run_final to true to train model on full dataset\n",
    "# run_final is used when generating predictions for kaggle\n",
    "run_final = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_final:\n",
    "    train_percent = 1\n",
    "else:\n",
    "    train_percent = 0.8\n",
    "    \n",
    "total_sample = 200000\n",
    "train_sample = int(train_percent * total_sample)\n",
    "\n",
    "allRatings = np.zeros(total_sample)   # store all ratings\n",
    "train_user_diction = {}   # store data using userID as keys\n",
    "train_item_diction = {}   # store data using itemID as keys\n",
    "test_user_diction = {}   # store data using userID as keys\n",
    "test_item_diction = {}   # store data using itemID as keys\n",
    "data = np.zeros((total_sample, 3), dtype=object) # store entire data as an array\n",
    "\n",
    "index = 0\n",
    "for l in readFile(\"../data/train.json\"):\n",
    "    allRatings[index] = int(l['rating'])\n",
    "    \n",
    "    data[index] = l['reviewerID'],l['itemID'],int(l['rating'])\n",
    "    if index < train_sample:\n",
    "        if l['reviewerID'] not in train_user_diction:\n",
    "            train_user_diction[l['reviewerID']] = [[l['itemID'],int(l['rating'])]]\n",
    "        else:\n",
    "            train_user_diction[l['reviewerID']].append([l['itemID'],int(l['rating'])])\n",
    "        if l['itemID'] not in train_item_diction:\n",
    "            train_item_diction[l['itemID']] = [[l['reviewerID'], int(l['rating'])]]\n",
    "        else:\n",
    "            train_item_diction[l['itemID']].append([l['reviewerID'], int(l['rating'])])\n",
    "    else:\n",
    "        if l['reviewerID'] not in test_user_diction:\n",
    "            test_user_diction[l['reviewerID']] = [[l['reviewerID'], int(l['rating'])]]\n",
    "        else:\n",
    "            test_user_diction[l['reviewerID']].append([l['reviewerID'], int(l['rating'])])\n",
    "        if l['itemID'] not in test_item_diction:\n",
    "            test_item_diction[l['itemID']] = [[l['reviewerID'], int(l['rating'])]]\n",
    "        else:\n",
    "            test_item_diction[l['itemID']].append([l['reviewerID'], int(l['rating'])])\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 2 train mse 0.9266872608584007\n",
      "model 2 train rmse 0.9626459685982177\n"
     ]
    }
   ],
   "source": [
    "# model 1: alpha and beta_u\n",
    "\n",
    "cutoff_user = 10\n",
    "# initialize alpha and beta\n",
    "train_user_list = list(train_user_diction.keys())\n",
    "alpha_2 = 0\n",
    "beta_u = {}\n",
    "delta = 100  # difference between iterations\n",
    "while delta >= 10**-5: # set the error tolerance \n",
    "    local_alpha = 0\n",
    "    for user in train_user_list:   # we first update alpha\n",
    "        user_rating = np.array(train_user_diction[user])[:,1]\n",
    "        if user not in beta_u:\n",
    "            local_alpha += np.sum(user_rating.astype(int))\n",
    "        else:\n",
    "            local_alpha += np.sum(user_rating.astype(int) - beta_u[user])\n",
    "    local_alpha = local_alpha/train_sample\n",
    "    \n",
    "    for user in train_user_list:  # we then update beta\n",
    "        user_rating = np.array(train_user_diction[user])[:,1]\n",
    "        # beta_u[user] = np.sum(user_rating.astype(int) - local_alpha)/len(train_user_diction[user])\n",
    "        beta_u[user] = min(1,len(train_user_diction[user])/cutoff_user)*np.sum(user_rating.astype(int) - local_alpha)/len(train_user_diction[user])\n",
    "    \n",
    "    delta = abs(local_alpha - alpha_2)  # calculate the difference of alphas between epoch\n",
    "    alpha_2 = local_alpha # update global alpha\n",
    "\n",
    "\n",
    "##### calculate training mse and testing mse #######################################################\n",
    "test_user_list = list(test_user_diction.keys())\n",
    "train_label = np.zeros(train_sample)\n",
    "train_prediction = np.zeros(train_sample)\n",
    "test_label = np.zeros(total_sample-train_sample)\n",
    "test_prediction = np.zeros(total_sample - train_sample)\n",
    "index = 0\n",
    "for user in train_user_list:\n",
    "    user_rating = np.array(train_user_diction[user])[:,1].astype(int)\n",
    "    train_label[index: index+len(user_rating)] = user_rating\n",
    "    train_prediction[index: index+len(user_rating)] = alpha_2 + beta_u[user]\n",
    "    index += len(user_rating)\n",
    "\n",
    "index = 0\n",
    "for user in test_user_list:\n",
    "    user_rating = np.array(test_user_diction[user])[:,1].astype(int)\n",
    "    test_label[index: index+len(user_rating)] = user_rating\n",
    "    if user not in train_user_list:\n",
    "        test_prediction[index: index+len(user_rating)] = alpha_2\n",
    "    else:\n",
    "        test_prediction[index: index+len(user_rating)] = alpha_2 + beta_u[user]\n",
    "    index += len(user_rating)\n",
    "        \n",
    "train_error_2 = mse(train_label, train_prediction)\n",
    "print('model 2 train mse', train_error_2)\n",
    "print('model 2 train rmse', np.sqrt(train_error_2))\n",
    "if not run_final:\n",
    "    test_error_2 = mse(test_label, test_prediction)\n",
    "    print('model 2 testing mse', test_error_2)\n",
    "    print('model 2 testing rmse', np.sqrt(test_error_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_final:\n",
    "    predictions = open(\"predictions_Rating_alpha_betau_reg{}.txt\".format(cutoff_user), 'w')\n",
    "    for l in open(\"../data/pairs_Rating.txt\"):\n",
    "        if l.startswith(\"reviewerID\"):\n",
    "            predictions.write(l) # header\n",
    "            continue\n",
    "        u,i = l.strip().split('-')\n",
    "        if u in train_user_list:\n",
    "            predictions.write(u + '-' + i + ',' + str(alpha_2 + beta_u[u]) + '\\n')\n",
    "        else:\n",
    "            predictions.write(u + '-' + i + ',' + str(alpha_2) + '\\n')\n",
    "\n",
    "    predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/d2l/lib/python3.7/site-packages/ipykernel_launcher.py:32: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53c409dbdaa4a4f93a65fbdee38a92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19914.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/d2l/lib/python3.7/site-packages/ipykernel_launcher.py:39: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62029c7e74f43fcafd7b94bf280fe72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model 3 train mse 1.0709415550690493\n",
      "model 3 train rmse 1.0348630610225922\n"
     ]
    }
   ],
   "source": [
    "# model 2: alpha and beta_i\n",
    "\n",
    "cutoff_item = 15\n",
    "# initialize alpha and beta\n",
    "train_item_list = list(train_item_diction.keys())\n",
    "alpha_3 = 0\n",
    "beta_i = {}\n",
    "delta = 100\n",
    "while delta >= 10**-5:\n",
    "    local_alpha = 0\n",
    "    for item in train_item_list: # we first update alpha\n",
    "        item_rating = np.array(train_item_diction[item])[:,1]\n",
    "        if item not in beta_i:\n",
    "            local_alpha += np.sum(item_rating.astype(int))\n",
    "        else:\n",
    "            local_alpha += np.sum(item_rating.astype(int) - beta_i[item])\n",
    "    local_alpha = local_alpha/train_sample\n",
    "    \n",
    "    for item in train_item_list: # we then update beta\n",
    "        item_rating = np.array(train_item_diction[item])[:,1]\n",
    "        # beta_i[item] = np.sum(item_rating.astype(int) - local_alpha)/len(train_item_diction[item])\n",
    "        beta_i[item] = min(1,len(train_item_diction[item])/cutoff_item)*np.sum(item_rating.astype(int) - local_alpha)/len(train_item_diction[item])\n",
    "    delta = abs(local_alpha - alpha_3)\n",
    "    alpha_3 = local_alpha\n",
    "\n",
    "test_item_list = list(test_item_diction.keys())\n",
    "train_label = np.zeros(train_sample)\n",
    "train_prediction = np.zeros(train_sample)\n",
    "test_label = np.zeros(total_sample - train_sample)\n",
    "test_prediction = np.zeros(total_sample - train_sample)\n",
    "index = 0\n",
    "for item in tqdm(train_item_list, total = len(train_item_list)):\n",
    "    item_rating = np.array(train_item_diction[item])[:,1].astype(int)\n",
    "    train_label[index: index+len(item_rating)] = item_rating\n",
    "    train_prediction[index: index+len(item_rating)] = alpha_3 + beta_i[item]\n",
    "    index += len(item_rating)\n",
    "\n",
    "index = 0\n",
    "for item in tqdm(test_item_list, total = len(test_item_list)):\n",
    "    item_rating = np.array(test_item_diction[item])[:,1].astype(int)\n",
    "    test_label[index: index+len(item_rating)] = item_rating\n",
    "    if item not in train_item_list:\n",
    "        test_prediction[index: index+len(item_rating)] = alpha_3\n",
    "    else:\n",
    "        test_prediction[index: index+len(item_rating)] = alpha_3 + beta_i[item]\n",
    "    index += len(item_rating)\n",
    "        \n",
    "train_error_3 = mse(train_label, train_prediction)\n",
    "print('model 3 train mse', train_error_3)\n",
    "print('model 3 train rmse', np.sqrt(train_error_3))\n",
    "if not run_final:\n",
    "    test_error_3 = mse(test_label, test_prediction)\n",
    "    print('model 3 testing mse', test_error_3)\n",
    "    print('model 3 testing rmse', np.sqrt(test_error_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_final:\n",
    "    predictions = open(\"predictions_Rating_alpha_betai_reg{}.txt\".format(cutoff_item), 'w')\n",
    "    index = 0\n",
    "    for l in open(\"../data/pairs_Rating.txt\"):\n",
    "        if l.startswith(\"reviewerID\"):\n",
    "            predictions.write(l) # header\n",
    "            continue\n",
    "        u,i = l.strip().split('-')\n",
    "        if i in train_item_list:\n",
    "            predictions.write(u + '-' + i + ',' + str(alpha_3 + beta_i[i]) + '\\n')\n",
    "        else:\n",
    "            predictions.write(u + '-' + i + ',' + str(alpha_3) + '\\n')\n",
    "        index+=0\n",
    "\n",
    "    predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/d2l/lib/python3.7/site-packages/ipykernel_launcher.py:69: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54761e90adb461986ddf84ff7d4ed38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/d2l/lib/python3.7/site-packages/ipykernel_launcher.py:72: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a3f7f792e943988ceca689ca8b704c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model 4 train mse 0.8069862430497315\n",
      "model 4 train rmse 0.8983241302835695\n"
     ]
    }
   ],
   "source": [
    "# model 3: alpha and beta_u and beta_i\n",
    "cutoff_user = 10\n",
    "cutoff_item = 15\n",
    "# initialize alpha and beta\n",
    "alpha_4 = 0\n",
    "beta_u = {}\n",
    "beta_i = {}\n",
    "delta = 100\n",
    "epoch = 0\n",
    "while delta >= 10**-5:\n",
    "    local_alpha = 0\n",
    "    local_beta_u = {}\n",
    "    local_beta_i = {}\n",
    "    \n",
    "    for user, item, rating in data[:train_sample]:  # we first update alpah\n",
    "        if user not in beta_u:\n",
    "            if item not in beta_i:\n",
    "                local_alpha += int(rating)/train_sample\n",
    "            else:\n",
    "                local_alpha += (int(rating) - beta_i[item])/train_sample\n",
    "        else:\n",
    "            if item not in beta_i:\n",
    "                local_alpha += (int(rating) - beta_u[user])/train_sample\n",
    "            else:\n",
    "                local_alpha += (int(rating) - beta_u[user] - beta_i[item])/train_sample\n",
    "    delta = abs(alpha_4 - local_alpha)\n",
    "    alpha_4 = local_alpha\n",
    "    \n",
    "    for user, item, rating in data[:train_sample]:  # we first update beta_u\n",
    "        if item not in beta_i:\n",
    "            if user not in local_beta_u:\n",
    "                local_beta_u[user] = (int(rating) - alpha_4)/len(train_user_diction[user])\n",
    "            else:\n",
    "                local_beta_u[user] += (int(rating) - alpha_4)/len(train_user_diction[user])\n",
    "        else:\n",
    "            if user not in local_beta_u:\n",
    "                local_beta_u[user] = (int(rating) - alpha_4 - beta_i[item])/len(train_user_diction[user])\n",
    "            else:\n",
    "                local_beta_u[user] += (int(rating) - alpha_4 - beta_i[item])/len(train_user_diction[user])\n",
    "                \n",
    "    for user in train_user_list: # we then update beta\n",
    "        local_beta_u[user] = min(1,len(train_user_diction[user])/cutoff_user)*local_beta_u[user]\n",
    "        \n",
    "        \n",
    "    if epoch !=0 :\n",
    "        delta = max(delta, abs(list(local_beta_u.values())[0] - list(beta_u.values())[0]))\n",
    "    beta_u = local_beta_u\n",
    "    \n",
    "    \n",
    "    for user, item, rating in data[:train_sample]:  # we first update beta_i\n",
    "        if item not in local_beta_i:\n",
    "            local_beta_i[item] = (int(rating) - alpha_4 - beta_u[user])/len(train_item_diction[item])\n",
    "        else:\n",
    "            local_beta_i[item] += (int(rating) - alpha_4 - beta_u[user])/len(train_item_diction[item])\n",
    "    \n",
    "    for item in train_item_list: # we then update beta\n",
    "        # beta_i[item] = np.sum(item_rating.astype(int) - local_alpha)/len(train_item_diction[item])\n",
    "        local_beta_i[item] = min(1,len(train_item_diction[item])/cutoff_item)*local_beta_i[item]\n",
    "        \n",
    "    if epoch != 0:\n",
    "        delta = max(delta, abs(list(local_beta_i.values())[0] - list(beta_i.values())[0]))\n",
    "    \n",
    "    beta_i = local_beta_i\n",
    "    epoch += 1\n",
    "\n",
    "\n",
    "train_prediction = np.zeros(train_sample)\n",
    "test_prediction = np.zeros(total_sample - train_sample)\n",
    "for index, (user, item, rating) in tqdm(enumerate(data[:train_sample]), total=train_sample):\n",
    "    train_prediction[index] = alpha_4 + beta_u[user] + beta_i[item]\n",
    "\n",
    "for index, (user, item, rating) in tqdm(enumerate(data[train_sample:]), total=total_sample-train_sample):\n",
    "    if user in beta_u:\n",
    "        if item in beta_i:\n",
    "            test_prediction[index] = alpha_4 + beta_u[user] + beta_i[item]\n",
    "        else:\n",
    "            test_prediction[index] = alpha_4 + beta_u[user]\n",
    "    else:\n",
    "        if item in beta_i:\n",
    "            test_prediction[index] = alpha_4 + beta_i[item]\n",
    "        else:\n",
    "            test_prediction[index] = alpha_4\n",
    "            \n",
    "        \n",
    "train_error_4 = mse(allRatings[:train_sample], train_prediction)\n",
    "print('model 4 train mse', train_error_4)\n",
    "print('model 4 train rmse', np.sqrt(train_error_4))\n",
    "\n",
    "if not run_final:\n",
    "    test_error_4 = mse(allRatings[train_sample:], test_prediction)\n",
    "    print('model 4 testing mse', test_error_4)\n",
    "    print('model 4 testing rmse', np.sqrt(test_error_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_final:\n",
    "    predictions = open(\"predictions_Rating_alpha_betau_betai_reguser{}_regitem{}.txt\".format(cutoff_user, cutoff_item), 'w')\n",
    "    for l in open(\"../data/pairs_Rating.txt\"):\n",
    "        if l.startswith(\"reviewerID\"):\n",
    "            predictions.write(l) # header\n",
    "            continue\n",
    "        u,i = l.strip().split('-')\n",
    "        if u in train_user_list:\n",
    "            if i in train_item_list:\n",
    "                predictions.write(u + '-' + i + ',' + str(alpha_4 + beta_i[i] + beta_u[u]) + '\\n')\n",
    "            else:\n",
    "                predictions.write(u + '-' + i + ',' + str(alpha_4 + beta_u[u]) + '\\n')\n",
    "        else:\n",
    "            if i in train_item_list:\n",
    "                predictions.write(u + '-' + i + ',' + str(alpha_4 + beta_i[i]) + '\\n')\n",
    "            else:\n",
    "                predictions.write(u + '-' + i + ',' + str(alpha_4) + '\\n')\n",
    "\n",
    "    predictions.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
